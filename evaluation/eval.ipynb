{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e71ed39",
   "metadata": {},
   "source": [
    "Edit-Distance/ Normalized Edit-Distance/ Mirco-Precision, -Recall, -F1 score for Morfessor Segmentation (boundary level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286de7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit distance\n",
    "def edit_distance(seq1, seq2):\n",
    "\n",
    "    n, m = len(seq1), len(seq2)\n",
    "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(m + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            if seq1[i - 1] == seq2[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            dp[i][j] = min(\n",
    "                dp[i - 1][j] + 1,      # deletion\n",
    "                dp[i][j - 1] + 1,      # insertion\n",
    "                dp[i - 1][j - 1] + cost # substitution\n",
    "            )\n",
    "    return dp[n][m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72188b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for calculating boundary level accuracy\n",
    "import re\n",
    "\n",
    "def get_boundaries(segmentation):\n",
    "\n",
    "    tokens = re.split(r\"[-\\s]+\", segmentation.strip())\n",
    "    boundaries = []\n",
    "    idx = 0\n",
    "    for token in tokens[:-1]:\n",
    "        idx += len(token)\n",
    "        boundaries.append(idx)\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ffc98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f1_prec_rec(pred, gold):\n",
    "\n",
    "    pred_bounds = set(get_boundaries(pred))\n",
    "    gold_bounds = set(get_boundaries(gold))\n",
    "\n",
    "    correct = len(pred_bounds & gold_bounds)\n",
    "    pred_count = len(pred_bounds)\n",
    "    gold_count = len(gold_bounds)\n",
    "\n",
    "    precision = correct / pred_count if pred_count > 0 else 0.0\n",
    "    recall = correct / gold_count if gold_count > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change language, short and file path\n",
    "language = 'Lezgi'\n",
    "short = 'lez'\n",
    "\n",
    "gold = []\n",
    "with open (f'{language}/{short}-train-track2-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\m\"):\n",
    "            gold.append(line.strip()[3:])\n",
    "\n",
    "\n",
    "selftrained = []\n",
    "with open (f'{language}/{short}-train-track1-covered-selftrained-train', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\m\"):\n",
    "            selftrained.append(line.strip()[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77130097",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "norm_distances = []\n",
    "pr = []\n",
    "f = []\n",
    "\n",
    "total_correct = 0\n",
    "total_pred = 0\n",
    "total_gold = 0\n",
    "\n",
    "for pred, gold in zip(selftrained, gold):\n",
    "\n",
    "    pred_tokens = pred.replace(\"-\", \" \").split()\n",
    "    gold_tokens = gold.replace(\"-\", \" \").split()\n",
    "\n",
    "    b1 = get_boundaries(pred)\n",
    "    b2 = get_boundaries(gold)\n",
    "\n",
    "    dist = edit_distance(pred_tokens, gold_tokens)\n",
    "    p, r, f1 = calc_f1_prec_rec(pred, gold)\n",
    "\n",
    "    pred_bounds = set(get_boundaries(pred))\n",
    "    gold_bounds = set(get_boundaries(gold))\n",
    "    total_correct += len(pred_bounds & gold_bounds)\n",
    "    total_pred += len(pred_bounds)\n",
    "    total_gold += len(gold_bounds)\n",
    "\n",
    "    distances.append(dist)\n",
    "    norm_distances.append(dist/max(len(pred_tokens), len(gold_tokens)))\n",
    "    pr.append((p,r))\n",
    "    f.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ffa7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average edit distance per sentence\n",
    "avg = sum(distances)/len(distances)\n",
    "print(avg)\n",
    "\n",
    "# average NED per sentence\n",
    "norm_avg = sum(norm_distances)/len(norm_distances)\n",
    "print(norm_avg)\n",
    "\n",
    "# precision, recall and f1 scores\n",
    "micro_p = total_correct / total_pred if total_pred > 0 else 0\n",
    "micro_r = total_correct / total_gold if total_gold > 0 else 0\n",
    "micro_f1 = 2 * micro_p * micro_r / (micro_p + micro_r) if (micro_p + micro_r) > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9df0ca",
   "metadata": {},
   "source": [
    "Morpheme Level f1, Recall, Precision for morfessor segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change language, short and file path\n",
    "language = 'Gitksan'\n",
    "short = 'git'\n",
    "\n",
    "gold = []\n",
    "with open (f'{language}/{short}-train-track2-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\m\"):\n",
    "            gold.append(line.strip()[3:].replace('-', ' ').split())\n",
    "\n",
    "\n",
    "selftrained = []\n",
    "with open (f'{language}/{short}-train-track1-covered-selftrained-train', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\m\"):\n",
    "            selftrained.append(line.strip()[3:].replace('-', ' ').split())\n",
    "\n",
    "print(gold)\n",
    "print(selftrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def morpheme_pre_rec_f1(pred_list: List[List[str]], gold_list: List[List[str]]) -> Tuple[float, float, float]:\n",
    "\n",
    "    assert len(pred_list) == len(gold_list), \"length unequal\"\n",
    "\n",
    "    total_correct = 0\n",
    "    total_pred = 0\n",
    "    total_gold = 0\n",
    "\n",
    "    for pred_morphs, gold_morphs in zip(pred_list, gold_list):\n",
    "\n",
    "        total_pred += len(pred_morphs)\n",
    "        total_gold += len(gold_morphs)\n",
    "\n",
    "        for pred in pred_morphs:\n",
    "            if pred in gold_morphs:\n",
    "                total_correct += 1\n",
    "                gold_morphs = gold_morphs.copy()\n",
    "                gold_morphs.remove(pred)\n",
    "\n",
    "    precision = total_correct / total_pred if total_pred > 0 else 0.0\n",
    "    recall = total_correct / total_gold if total_gold > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45213f8",
   "metadata": {},
   "source": [
    "Impact of Word Frequency on Gloss Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# change number\n",
    "\n",
    "num = 5\n",
    "\n",
    "match num:\n",
    "    case 1:\n",
    "      language = 'Gitksan'\n",
    "      short = 'git'\n",
    "    case 2:\n",
    "      language = 'Lezgi'\n",
    "      short = 'lez'\n",
    "    case 3:\n",
    "      language = 'Natugu'\n",
    "      short = 'ntu'\n",
    "    case 4:\n",
    "      language = 'Tsez'\n",
    "      short = 'ddo'\n",
    "    case 5:\n",
    "      language = 'Savosavo'\n",
    "      short = 'savo'\n",
    "    case 6:\n",
    "      language = 'Yali'\n",
    "      short = 'apah'\n",
    "\n",
    "word_list = []\n",
    "with open (f'{language}/{short}-train-track1-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\t\"):\n",
    "            word_list.extend(line.strip()[3:].split())\n",
    "\n",
    "test_words = []\n",
    "with open (f'{language}/{short}-test-track1-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\t\"):\n",
    "            test_words.append(line.strip()[3:].split())\n",
    "\n",
    "gold_gloss = []\n",
    "with open (f'{language}/{short}-test-track1-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\g\"):\n",
    "            gold_gloss.append(line.strip()[3:].split())\n",
    "\n",
    "selfpredicted_gloss = []\n",
    "with open (f'{language}/{short}-output-preds', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\g\"):\n",
    "            selfpredicted_gloss.append(line.strip()[3:].split())\n",
    "\n",
    "#frequency of all words in training dataset\n",
    "word_freq = Counter(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd5221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each word, check if predicted correct. if correct, score = 1, else, score = 0\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "wordScores = defaultdict(list)\n",
    "for i in range(len(test_words)):\n",
    "    word = test_words[i]\n",
    "    gold = gold_gloss[i]\n",
    "    pred = selfpredicted_gloss[i]\n",
    "\n",
    "    # if predicted not enough, fill with 'UNK'\n",
    "    while len(pred) < len(gold):\n",
    "        pred.append('UNK')\n",
    "\n",
    "    for w, g, pr in zip(word, gold, pred):\n",
    "        score = 1 if pr.strip() == g.strip() else 0\n",
    "        wordScores[w].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = {\"OOV\": [], \"low\": [], \"medium\": [], \"high\": []}\n",
    "\n",
    "# sort words according to the frequency into bucktes and append the average score computed from code above\n",
    "\n",
    "for word, scores in wordScores.items():\n",
    "    avg_score = sum(scores) / len(scores)\n",
    "    freq = word_freq.get(word, 0)\n",
    "    if freq == 0:\n",
    "        buckets[\"OOV\"].append(avg_score)\n",
    "    elif freq <= 2:\n",
    "        buckets[\"low\"].append(avg_score)\n",
    "    elif freq <= 10:\n",
    "        buckets[\"medium\"].append(avg_score)\n",
    "    else:\n",
    "        buckets[\"high\"].append(avg_score)\n",
    "\n",
    "# calculate average score for each bucket\n",
    "for b in buckets:\n",
    "      if buckets[b]:\n",
    "          buckets[b] = sum(buckets[b]) / len(buckets[b])\n",
    "      else:\n",
    "          buckets[b] = 0.0\n",
    "\n",
    "print(buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96557c0d",
   "metadata": {},
   "source": [
    "Impact of Numbers of Morphemes for the Gloss Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change number\n",
    "num = 6\n",
    "\n",
    "match num:\n",
    "    case 1:\n",
    "      language = 'Gitksan'\n",
    "      short = 'git'\n",
    "    case 2:\n",
    "      language = 'Lezgi'\n",
    "      short = 'lez'\n",
    "    case 3:\n",
    "      language = 'Natugu'\n",
    "      short = 'ntu'\n",
    "    case 4:\n",
    "      language = 'Tsez'\n",
    "      short = 'ddo'\n",
    "    case 5:\n",
    "      language = 'Savosavo'\n",
    "      short = 'savo'\n",
    "    case 6:\n",
    "      language = 'Yali'\n",
    "      short = 'apah'\n",
    "\n",
    "gold_gloss = []\n",
    "with open (f'{language}/{short}-test-track1-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\g\"):\n",
    "            gold_gloss.append(line.strip()[3:].split())\n",
    "\n",
    "selfpredicted_gloss = []\n",
    "with open (f'{language}/{short}_output_preds', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\g\"):\n",
    "            selfpredicted_gloss.append(line.strip()[3:].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# number of morphemes, sorted after num of morphemes\n",
    "group_counts = defaultdict(int)\n",
    "# correct predicted unsplitted morpheme\n",
    "word_correct = defaultdict(int)\n",
    "# number of splitted morphemes\n",
    "morpheme_total = defaultdict(int)\n",
    "# correct predicted splitted morpheme\n",
    "morpheme_correct = defaultdict(int)\n",
    "\n",
    "for i in range(min(len(gold_gloss), len(selfpredicted_gloss))):\n",
    "    gold = gold_gloss[i]\n",
    "    pred = selfpredicted_gloss[i]\n",
    "\n",
    "    while len(pred) < len(gold):\n",
    "        pred.append('UNK')\n",
    "\n",
    "    for gg, pr in zip(gold, pred):\n",
    "\n",
    "        gold_parts = gg.split(\"-\")\n",
    "        pred_parts = pr.split(\"-\")\n",
    "        n = len(gold_parts)\n",
    "\n",
    "        group_counts[n] += 1\n",
    "\n",
    "        if gg == pr:\n",
    "            word_correct[n] += 1\n",
    "\n",
    "        for g, p in zip(gold_parts, pred_parts):\n",
    "            if g == p:\n",
    "                morpheme_correct[n] += 1\n",
    "\n",
    "        morpheme_total[n] += max(len(gold_parts), len(pred_parts))\n",
    "\n",
    "for n in sorted(group_counts.keys()):\n",
    "    word_acc = word_correct[n] / group_counts[n]\n",
    "    morph_acc = morpheme_correct[n] / morpheme_total[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97bf65e",
   "metadata": {},
   "source": [
    "TTR and OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "language = 'Yali'\n",
    "short = 'apah'\n",
    "\n",
    "train_words = []\n",
    "with open (f'{language}/{short}-train-track1-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\t\"):\n",
    "            train_words.extend(line.strip()[3:].split())\n",
    "\n",
    "test_words = []\n",
    "with open (f'{language}/{short}-test-track1-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\t\"):\n",
    "            test_words.extend(line.strip()[3:].split())\n",
    "\n",
    "train_morph = []\n",
    "with open (f'{language}/{short}-train-track2-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\m\"):\n",
    "            l = line.strip()[3:]\n",
    "            train_morph.extend(re.split(r'[-\\s]+', l))\n",
    "\n",
    "test_morph = []\n",
    "with open (f'{language}/{short}-test-track2-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\m\"):\n",
    "            l = line.strip()[3:]\n",
    "            test_morph.extend(re.split(r'[-\\s]+', l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTR\n",
    "\n",
    "unique_tok_train = set(train_words)\n",
    "unique_tok_test = set(test_words)\n",
    "\n",
    "ttr_train = len(unique_tok_train) / len(train_words)\n",
    "ttr_test = len(unique_tok_test) / len(test_words)\n",
    "\n",
    "print(f'TTR train: {ttr_train}, TTR test: {ttr_test}')\n",
    "\n",
    "# OOV\n",
    "oov_num = sum(1 for word in test_words if word not in train_words)\n",
    "oov = oov_num / len(test_words)\n",
    "\n",
    "oov_num2 = sum(1 for morph in test_morph if morph not in train_morph)\n",
    "oov_morph = oov_num2 / len(test_morph)\n",
    "\n",
    "print(f'OOV words: {oov}')\n",
    "print(f'OOV morph: {oov_morph}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a64c6e",
   "metadata": {},
   "source": [
    "Number of sentences in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac69ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 6\n",
    "\n",
    "match num:\n",
    "    case 1:\n",
    "      language = 'Gitksan'\n",
    "      short = 'git'\n",
    "    case 2:\n",
    "      language = 'Lezgi'\n",
    "      short = 'lez'\n",
    "    case 3:\n",
    "      language = 'Natugu'\n",
    "      short = 'ntu'\n",
    "    case 4:\n",
    "      language = 'Tsez'\n",
    "      short = 'ddo'\n",
    "    case 5:\n",
    "      language = 'Savosavo'\n",
    "      short = 'savo'\n",
    "    case 6:\n",
    "      language = 'Yali'\n",
    "      short = 'apah'\n",
    "\n",
    "t = 0\n",
    "d = 0\n",
    "tr = 0\n",
    "\n",
    "with open (f'{language}/{short}-test-track1-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\t\"):\n",
    "            t += 1\n",
    "\n",
    "with open (f'{language}/{short}-dev-track1-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\t\"):\n",
    "            d += 1\n",
    "\n",
    "with open (f'{language}/{short}-train-track1-uncovered', \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"\\\\t\"):\n",
    "            tr += 1\n",
    "\n",
    "print(f\"Language {language} has {t} sentences in test set, {d} sentences for dev and {tr} sentences for training set\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
